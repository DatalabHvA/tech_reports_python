{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc53274",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1>DataLab HvA - serie Machine Learning Python - Tech report 6</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92d689",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h2>K-fold crossvalidatie en grid search</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37623910",
   "metadata": {},
   "source": [
    "### 0. Doel van deze les\n",
    "Je leert hoe je voor diverse modellen waarin de waarde van zogenaamde *hyperparatmeters* gekozen (*getuned*) moet worden dit kan middels een methode van *grid search*. Om je hierbij middels tussenresultaten op je trainingsdata zuiver te laten leiden in een beslissing voor de beste keuze maak je gebruik van een methode die *k-fold cross validatie* heet. We leren je hier hoe je deze methoden kunt gebruiken in het package `sklearn`. \n",
    "\n",
    "Naast de recht-toe-recht aan grid search bespreken we ook (in sommige gevallen) efficiëntere algoritmen zoals:\n",
    "- Random Search en\n",
    "- Baysian Search\n",
    "\n",
    "Deze les gaat *niet* over specifieke algoritmen, de modellen in dit Tech Report zijn zuiver illustratief. \n",
    "\n",
    "### 1. Introductie hyperparameters\n",
    "Vaak is het nodig bij het optimaliseren van een machine learning model enkele *hyperparameters* vast te stellen. *Hyperparameters* moeten niet verward worden met de *modelcoëfficiënten* die in het optimalisatieproces van training worden bepaald. De *hyperparameters* van een model worden voorafgaande aan het trainen van een (definitief) model vastgesteld. Denk aan:  \n",
    "- het *maximale diepte*, de *cost complexity* en de *methode om het informatiecriterium vast te stellen* voor een beslisboom (zie TR 7 en 8)\n",
    "- het *aantal bomen* en *het aantal variabelen per boom* in een random forest (zie TR 9 en 10)  \n",
    "- de *kostenparameters* en de *inproductkeuze + parameters voor de kernel* voor een Supprot Vector Machine (zie TR 11 en 12)  \n",
    "- het aantal *layers*, *aantal neuronen per layer*, de *activiatiefunctie(s)* in een neuraal netwerk\n",
    "\n",
    "Modelcoëficiënten daarentegen zijn bijvoorbeeld de waarden voor $\\alpha$ en $\\beta_i$ voor een regressiemodel: \n",
    "$$ y = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_k x_k +\\epsilon$$\n",
    "\n",
    "Ga na dat een lineair regressiemodel verder geen hyperparameters heeft. \n",
    "\n",
    "Andere voorbeelden van modelcoëfficiënten zijn:\n",
    "- de *gekozen variabelen met grenswaarden voor de splitsingen* in de vertakkingen van een beslisboom \n",
    "- de waarde van de de *gewichten* in een neuraal netwerk  \n",
    "\n",
    "De waarden van deze modelcoëfficënten worden gevonden in het optimalisatiealgoritme dat werkzaam is bij het trainen van een specifiek modeltype, maar *voorafgaande daaraan* zijn de *hyperparameters* al gekozen. Het maak echter wel uit *hoe* je deze kiest: **de modelprestatie is ervan afhankelijk**. Hoe stellen we deze dan vast?\n",
    "\n",
    "Wat **niet** mag in een CRISP-DM methodiek is dat je diverse waarden voor hyperparameters uitprobeert en van de getrainde modellen vervolgens telkens de prestatie op de *test data* observeert en dan dát model kiest dat hierop het beste presteert. Ga na dat je dan de testset als een *tweede trainingset* hebt laten functioneren waardoor je *geen* betrouwbare uitspraak kan doen m.b.t. de te verwachten modelprestatie op *werkelijk* nieuwe data!\n",
    "\n",
    "### 2. K-fold cross validatie\n",
    "Een oplossing voor het omzeilen van het voortijdige gebruik van de test dataset is om *binnen de traindata* een deel af te splitsen die *tijdelijk* dienst doet als testset. Deze *tijdelijke testset afkomstig uit de train data* noemen we een **validatie dataset**. In het vervolg gaan we er vanuit dat er een prestatiemaat (performance metric) gekozen is die modelscores onderling vergelijkt, meer daarover in *TR3 - Prestatiematen en modelscore*. \n",
    "\n",
    "#### Eerste poging\n",
    "We zouden bijvoorbeeld als volgt kunnen werken:  \n",
    "- splist 20% van de traindata af als validatie dataset   \n",
    "- met de 80% resterende train dataset trainen we diverse modellen, we passen steeds hyperparameter(s) aan  \n",
    "- bepaal de modelscore van ieder getraind model op de validatieset en  \n",
    "- kies uiteindelijk de hyperparameter(combinatie) die de beste modelscore gaf  \n",
    "- ! train met *deze* hyperparameter(combinatie) het definitieve model op de *complete train dataset*  \n",
    "- stel de modelscore van dit eindmodel vast op de *test dataset*  \n",
    "- rapporteer de modelscore etc... (aanpassingen aan het model **niet** meer mogelijk)\n",
    "\n",
    "Dat zou een prima werkwijze kunnen zijn, maar bedenk:  \n",
    "- de resterende 80% van de traindata bevat mogelijk significant minder informatie dan de oorspronkelijke 100%  \n",
    "- de validatieset (20% van de traindata) zou wel eens niet zo representatief kunnen zijn voor een set nieuwe data  \n",
    "\n",
    "#### k-fold cross validatie\n",
    "Hierdoor kan de *toevallige* keuze van de split in *resterende train dataset* vs *validatie dataset* wel eens een vertekend beeld gaan geven van de te verwachten prestaties op een nieuwe dataset. Om dit effect te elimineren passen we de werkwijze hierboven een beetje aan. Het stappenplan hieronder is een beschrijving van de methode van k-fold cross validatie, met k = 5. Meer specifiek: de beschreven *Stap 2* is de k-fold cross validatie, het doorlopen van verschillende opties voor de hyperparameters wordt meer uitgediept in de sectie *grid search*.\n",
    "\n",
    "- Stap 1\n",
    "    - splist de traindata in (k=) 5 gelijke sets (allen dus 20% van de train dataset) - we noemen deze de 5 *folds*   \n",
    "    - nummer deze sets als fold-1, fold-2, fold-3, fold-4 en fold-5  \n",
    "- Stap 2  \n",
    "    - kies een (combinatie van) waarde(n) voor de hyperparameter(s)\n",
    "    - Stap 3  \n",
    "        - Kies fold-1 uit als validatieset \n",
    "        - met de overige sets (fold-2, fold-3, fold-4 en fold-5, dus 80% resterende train dataset) trainen we een model met de gekozen hyperparameter(combinatie)\n",
    "        - test de performance van dit model op de validatieset (nu dus fold-1) en  \n",
    "        - leg deze performance vast  \n",
    "    - herhaal Stap 3 maar dan achtereenvolgens met één van de andere folds als validatieset (en de overigen voor resterende train dataset)  \n",
    "    - middel de 5 gevonden modelscores, deze score hoort bij de gekozen hyperparametercombinatie in Stap 2  \n",
    "- Herhaal Stap 2 voor een andere (combinatie van) waarde(n) voor de hyperparameter(s)\n",
    "- Kies uiteindelijk die (combinatie van) waarde(n) voor de hyperparameter(s) die het beste (gemiddelde) modelscore gaf\n",
    "- Stap 4  \n",
    "    - ! train met *deze* hyperparametercombinatie het definitieve model op de *complete train dataset*  \n",
    "    - stel de modelscore van dit eindmodel vast op de *test dataset*  \n",
    "    - rapporteer de modelscore etc... (aanpassingen aan het model **niet** meer mogelijk)\n",
    "\n",
    "Lees [hier](https://scikit-learn.org/stable/modules/cross_validation.html) meer over de methode in `sklearn`, je vindt er ook verhelderende grafische voorstellingen van het boven beschreven proces. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9612de",
   "metadata": {},
   "source": [
    "#### Voorbeeld in sklearn\n",
    "`sklearn` heeft standaardmethoden die bovenstaande methode toepassen, je hoeft de stappen dus niet zelf stap voor stap uit te voeren. De in het voorbeeld boven gekozen waarde *k = 5* folds is een keuze, vaak de *default*. Ga wel na dat hoe groter k is, hoe vaker een model getraind zal worden per (combinatie van) hyperparameter(s) en dat de resterende traindata die daarbij wordt gebruikt ook groter per keer is. Voor sommige (complexe) modeltypen kan dit nogal veel van het geheugen en de processor van de computer vergen, houd daar rekening mee! \n",
    "\n",
    "We kiezen in het voorbeeld als volgt:  \n",
    "- Stap 0:   \n",
    "    - we kiezen als modeltype de *beslisboom voor classificatie*  (zie ook TR 8)  met   \n",
    "    - performace metric voor de modelscore: de *accuracy*   \n",
    "    - op een dataset `iris`\n",
    "- Stap 1, we kiezen  \n",
    "    - k = 6  \n",
    "- Stap 2, we kiezen  \n",
    "    - costcomplexity parameter = 1\n",
    "    - als methode om het informatiecriterium vast te stellen: `gini`  \n",
    "    - de maximale diepte van de boom: 3\n",
    "    \n",
    "We gaan hieronder *niet* verder met het kiezen van andere hyperparametercombinaties, daarover verderop meer bij de sectie *grid search*. We doorlopen Stap 2 (de k-fold cross validatie) voor slechts één gekozen set hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voor de dataset en plots\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Voor het bewerken en inspecteren van de data\n",
    "import pandas as pd\n",
    "\n",
    "# Voor het afsplitsen van een train- en test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Voor het modelleren\n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1596c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden van een standaard dataset uit package scikit learn\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "y = pd.Series(iris.target)\n",
    "\n",
    "# Split in training en test data \n",
    "# random_state kiezen zorgt voor reproduceerbaarheid van dit resultaat - gebruik dat ! Een andere waarde is uiteraard ook prima\n",
    "# we kiezen voor een verhouden train - test van 70% - 30%. Andere keuzen kunnen ook!\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.30,random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e54fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methode cross validatie uit sklearn en metrcics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#Definitie Model Beslisboom voor classificatie, we kiezen:\n",
    "dtc = DecisionTreeClassifier(ccp_alpha=0.2,            #costcomplexity parameter = 0.2\n",
    "                             criterion = 'gini',       #als methode om het informatiecriterium vast te stellen: gini\n",
    "                             max_depth = 3,            #de maximale diepte van de boom: 3\n",
    "                             random_state=999)         # Dit is geen hyperparameter van het model, maar t.b.v. reproductie\n",
    "\n",
    "# Het aanroepen van de k-fold Cross Validatie (CV)\n",
    "scores = cross_val_score(dtc, X, y, cv=6, scoring='accuracy') #we kiezen k = 6 en modelscore: de accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac57901",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"De scores op de (k =) 6 verschillende folds waren: \", scores)\n",
    "print(\"Het gemiddelde van de scores op de (k =) 6 verschillende folds is: \", scores.mean())\n",
    "print(\"De standaarddeviatie van de scores op de (k =) 6 verschillende folds is: \", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f16393",
   "metadata": {},
   "source": [
    "Het valt op dat de variatie van de scores op de verschillende folds relatief groot is, waarmee tevens is geillustreerd dat het 6-voudig herhalen en het bepalen van het gemiddelde een representatiever beeld van de modelprestatie geven.\n",
    "\n",
    "De waarde van de gemiddelde score over de 6 folds zou niet ver van de score van het eindmodel op de testset moeten liggen. Je kunt dit eventueel zelf nagaan, maar wij blijven hier nog even van de testset af. Want nu hebben we onze resultaten van slechts één combinatie van hyperparameters, we willen ook andere combinaties langsgaan. Dit doen we op een systematische manier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b3131",
   "metadata": {},
   "source": [
    "### 3. Grid search\n",
    "Het systematisch doorlopen van verschillende combinaties van waarden van hyperparameters kan geautomatiseerd worden uitgevoerd in een zogenaamde *grid search*. Het *grid* waar het om gaat is een representatie van de combinaties van hyperparameterwaarden die je stuk-voor-stuk gaat uitproberen. \n",
    "\n",
    "We borduren voort op het voorbeeld hierboven. We zouden willen verkennen  \n",
    "- Stap 2, we willen proberen  \n",
    "    - costcomplexity parameter in waardebereik: 0.1, 1, 10, 100\n",
    "    - diverse methoden om het informatiecriterium vast te stellen: \"gini\", \"entropy\", \"log_loss\" \n",
    "    - diverse maximale diepten van de boom: 2, 3, 4, 5\n",
    "    \n",
    "**Opmerking**: heel vaak *heb je geen idee* welke waarden in de buurt liggen van een optimale waarde. Neem in dat geval grote stappen (zoals we nu bij de *costcomplexity parameter* hebben gedaan), met in het achterhoofd dat we straks bij een gevonden optimale waarde wat verder zouden kunnen *inzoomen* (je kunt het proces zo vaak herhalen als je maar wil).\n",
    "\n",
    "Deze parameterwaarden, oftwel ons 'grid', leggen we vast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a302589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vastleggen van grid van parameterwaarden voor hyperparametertuning\n",
    "parameters1={\"criterion\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "            \"ccp_alpha\" : [ 0.1, 1, 10, 100],\n",
    "               \"max_depth\" : [1, 2, 3, 4, 5],\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91496a6b",
   "metadata": {},
   "source": [
    "Vervolgens importeren we de methode Grid Search Cross Validatie van `sklearn`, lees meer over deze methode [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Het doorlopen van een parametergrid en het vaststellen van modelscores via k-fold cross validatie wordt hierin gecombineerd.\n",
    "\n",
    "Ga na dat we 3 x 4 x 5 = 60 gridpunten hebben waarmee we een model gaan trainen en evalueren op 6 fold-combinaties, dus dat we 60 x 6 = 360 modelevaluaties gaan doorlopen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989173b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importeer vanuit scikit learn package de tooling:\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fe82d",
   "metadata": {},
   "source": [
    "Het vastleggen / definieren van dit proces met de eerder genoemde keuzes gebeurt hieronder. Merk op dat het model zelf (`dtc`) heel algemeen wordt gedefinieerd en dat pas in de `GridSearchCV` verschillende parameterwaarden worden aangereikt (via `param_grid = parameters`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cbf8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=999)           # Dit is geen hyperparameter van het model, maar t.b.v. reproductie\n",
    "tuning_model = GridSearchCV(estimator = dtc, \n",
    "                            param_grid = parameters1,    # we doorlopen het zojuist gedefinieerde grid 'parameters1'\n",
    "                            scoring='accuracy',          # we kiezen modelscore: de accuracy\n",
    "                            cv=6,                        # we kiezen k = 6 in de k-fold CV\n",
    "                            verbose=1)                   # hiermee regel je de details van de output gedurende het trainen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ea33e",
   "metadata": {},
   "source": [
    "Hieronder starten we de evaluatie, dit kan soms lang duren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf03f6",
   "metadata": {},
   "source": [
    "We vragen ons af wat de beste combi is en de beste score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beste model: \", tuning_model.best_estimator_)\n",
    "print(\"Beste score:  accuracy = \", tuning_model.best_score_)\n",
    "print(\"Beste parameter combi: \", tuning_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e033a",
   "metadata": {},
   "source": [
    "#### Interpretatie eerste resultaten\n",
    "- 1. Het valt op dat de optimale `ccp_alpha=0.1` op de *rand* van het gekozen bereik zit  \n",
    "    - Nu zullen we ook verder waarden < 0.1 moeten verkennen (negatieve waarden kunnen hierbij in dit geval niet)\n",
    "- 2. `max_depth = 3` (midden in het interval) en `criterion='entropy` zijn geoptimaliseerd terwijl we verder hadden moeten kijken voor `ccp_alpha`. We doen er goed aan hier voorlopig *alle opties open te houden* \n",
    "\n",
    "Zie hieronder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21547840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vastleggen van grid van aangepaste parameterwaarden voor hyperparametertuning\n",
    "parameters2={\"criterion\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "            \"ccp_alpha\" : [ 0, 0.1, 0.2, 0.3],\n",
    "               \"max_depth\" : [1, 2, 3, 4, 5],\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=999)           # Dit is geen hyperparameter van het model, maar t.b.v. reproductie\n",
    "tuning_model = GridSearchCV(estimator = dtc, \n",
    "                            param_grid = parameters2,    # we doorlopen het zojuist gedefinieerde grid 'parameters2'\n",
    "                            scoring='accuracy',          # we kiezen modelscore: de accuracy\n",
    "                            cv=6,                        # we kiezen k = 6 in de k-fold CV\n",
    "                            verbose=1)                   # hiermee regel je de details van de output gedurende het trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dcd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a221327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beste model: \", tuning_model.best_estimator_)\n",
    "print(\"Beste score:  accuracy = \", tuning_model.best_score_)\n",
    "print(\"Beste parameter combi: \", tuning_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c56cc",
   "metadata": {},
   "source": [
    "#### Interpretatie tweede resultaten\n",
    "- We zien nu dat `DecisionTreeClassifier(ccp_alpha=0, max_depth=4, random_state=999)` het optimale model is  \n",
    "- met een beste (gemiddelde) accuracy op de *validatiesets* van accuracy =  0.96 (hoger dan eerder, gan na!)  \n",
    "- De waarden van `ccp_alpha=0` zit weer op de rand, maar deze waarde kan niet lager gekozen worden, dus hier eindigt de zoektocht  \n",
    "- De waarde `max_depth=4` is anders vastgesteld dan boven, dus mooi dat die niet te vroeg werd vastgezet! De waarde zit *niet* op de rand van het gekozen interval, deze parameter kan alleen geheeltallig zijn  \n",
    "- De waarde `'criterion': 'gini'` is anders vastgesteld dan boven, dus mooi dat die niet te vroeg werd vastgezet! - NB: omdat het de *default* is voor dit modeltype wordt deze niet expliciet vermeld bij `best_estimator_`\n",
    "\n",
    "Op basis van deze gevonden combinatie definieren we het eindmodel en doorlopen Stap 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ede41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitie\n",
    "dtc_opt = DecisionTreeClassifier(ccp_alpha=0, criterion = 'gini', max_depth=4, random_state=999) # criterion = 'gini' kan weggelaten\n",
    "\n",
    "#fitten op hele train dataset\n",
    "dtc_opt.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2378a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorspellen op de test dataset - NB: wordt hier dus voor het eerst gebruikt!\n",
    "predicted_y = dtc_opt.predict(test_X)\n",
    "\n",
    "#accuracy op test dataset\n",
    "print(\"De accuracy op de testset = \", metrics.accuracy_score(test_y, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598e503",
   "metadata": {},
   "source": [
    "Ga na dat de gevonden waarde op de test dataset niet veel afwijkt van de (gemiddelde) accuracy op de validatiesets van dit model in de grid search CV routine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99a91a",
   "metadata": {},
   "source": [
    "### 4 Werken met subset van de traindata\n",
    "Een inituïtief overzichtelijke manier om de grid search - die soms heel tijdrovend kan zijn als het model veel parameters heeft, het grid heel groot is, het aantal folds groot gekozen wordt en/of de traindataset erg groot, is het om de eerste stappen van de gridsearch te zetten o.b.v. een deel van de trainingsdata. Hieronder zie je hoe je bijvoobeeld de sets `subset_train_X`en `subset_train_y` kan aanmaken die uit een random selectie van 10% van de oorspronkelijke set bestaat. Je kun vervolgens de grid search uitvoeren zoals je wilt maar dan met `subset_train_X`en `subset_train_y` in plaats van `train_X`en `train_y`. \n",
    "\n",
    "**Let op**: als de oorspronkelijke set al niet zo erg groot is, kan dit een risico met zich meebrengen (niet representatieve set)! Voor het bovenstaande voorbeeld is er geen enkele aanleiding deze stap te zetten, de set is zelf al klein en het model simpel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3195f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Met het oog op de lange doorlooptijd gebruiken we een subsample van de train data voor het CV-grid search proces: \n",
    "# we kiezen om hiervoor met 30% van de data te werken - dit is een risico...\n",
    "import numpy as np\n",
    "n_subset = int(np.floor(len(train_X)*0.3)) #0.3 = 30% van de data \n",
    "\n",
    "from sklearn.utils import resample\n",
    "subset_train_X, subset_train_y = resample(train_X,train_y, n_samples = n_subset, random_state=0)\n",
    "\n",
    "print(subset_train_X.shape)\n",
    "print(subset_train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d5241",
   "metadata": {},
   "source": [
    "### 5. Random Search  \n",
    "Waar je nogal eens tegenaan kunt lopen in het proces van grid search is dat  \n",
    "- sommige modellen per keer heel lang trainen (oorzaak kan de hoeveelheid data zijn en/of de complexiteit van het algoritme)  \n",
    "- dat sommige modeltypen véél parameters kennen die je een grid search zou willen betrekken, het aantal te evalueren modellen loopt snel hoog op\n",
    "- je aanvankelijk niet weet in welke range de optimale parameterwaarde van een specifieke parameter gezocht moet worden, hierdoor volg je vaak een iteratieve procedure: groot bereik en later (stapsgewijs) steeds meer inzoomen rondom gevonden optimale waarde  \n",
    "- de methode om een deel van de traindata te gebruiken (vorige sectie) niet wenselijk is of te weinig oplost aan het probleem van heel lange evaluatietijd  \n",
    "\n",
    "Dit kan een heel tijdrovende zaak worden!\n",
    "\n",
    "Hier kan het uitkomst bieden als niet het *gehele* grid doorlopen wordt, maar een (random) gekozen selectie. Dit geeft in ieder geval vaak een eerste idee van de locatie binnen het grid waar het  optimum gevonden kan worden. \n",
    "\n",
    "Omdat er vaak ook parameters voor een modeltype bestaan die niet discreet, maar *continu* zijn, zou je in deze random procedure liever een verdeling dan een grid van een vast aantal punten willen meegeven. Dit kan door gebruik te maken van een verdelingsfunctie, hieronder ter illustratie een voorbeeld van de uniforme verdeling uit het package `scipy.stats`. Lees [hier](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html) eventueel meer info over deze functie. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43084805",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h2>Over onderstaande voorbeeld</h2>\n",
    "    We willen vooral wat codevoorbeelden geven en suggesties hoe te werk te gaan. Voor het voorbeeldmodel en dataset is het niet nodig om deze techniek te gebruiken, een heel fijnmazig grid runt nog steeds heel snel. De resultaten zijn ook niet spectaculair, maar voor meer complexe modellen en grotere datasets (zie bijvoorbeeld Random Forest modellen en Support vector Machines in andere Tech Reports uit deze serie) loont dit zeker de moeite! Probeer daar deze technieken vooral uit!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73093ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initieel definieren van het basismodel voor de grid search:\n",
    "dtc_rand = DecisionTreeClassifier(random_state=999)     \n",
    "\n",
    "# importeren uniform functie van package\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Vastleggen van grid van parameterwaarden voor hyperparametertuning, waarbij continue parameters als verdeling\n",
    "parameters_rand={\"criterion\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "             \"ccp_alpha\" : uniform(loc=0, scale=2),\n",
    "             \"max_depth\" : [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "             \"min_samples_split\" : uniform(loc=0, scale=0.001),\n",
    "             \"min_samples_leaf\" : uniform(loc=0, scale=0.01),\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bbe940",
   "metadata": {},
   "source": [
    "In scikit-learn is een functie `RandomizedSearchCV` die zeer verwant is aan de eerder gebruikte `GridSearchCV`, de parameters komen voor een belangrijk deel overeen, maar eentje is met name van belang: `n_iter = ... ` (defaulwaarde = 10). Hiermee kiezen we het aantal random punten uit het grid waarop we een model willen evalueren. Lees ook [deze info](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized grid search definieren met n_iter = 100 punten uit parameters_rand\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "tuning_model_rand  = RandomizedSearchCV(estimator = dtc_rand, param_distributions = parameters_rand, \n",
    "                                        random_state=9, \n",
    "                                        n_iter = 100, \n",
    "                                        scoring='accuracy',\n",
    "                                        cv=6,\n",
    "                                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285dff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start het proces\n",
    "tuning_model_rand.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a308ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(tuning_model_rand.cv_results_).sort_index(axis=1)[['rank_test_score','mean_test_score','param_ccp_alpha', 'param_criterion', 'param_max_depth',\n",
    "       'param_min_samples_leaf', 'param_min_samples_split']].sort_values(by=['rank_test_score'])\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2841846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#create seaborn boxplots by group\n",
    "sns.boxplot(data=results, x='param_criterion', y='mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8a516-f543-4608-b178-bc3660fca252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results[results[\"param_criterion\"]==\"entropy\"]\n",
    "hm1 = sns.heatmap(results[results[\"param_criterion\"]==\"entropy\"].pivot(index = 'param_max_depth', columns = 'param_ccp_alpha', values = 'mean_test_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754135b4",
   "metadata": {},
   "source": [
    "Een visualisatie van de ligging van de optimale waarden voor `'param_max_depth'` en `'param_ccp_alpha'` per gekozen split criterium: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9298c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(sns.heatmap(results[results[\"param_criterion\"]==\"entropy\"].pivot(index = 'param_max_depth', columns = 'param_ccp_alpha', values = 'mean_test_score')))\n",
    "#print(sns.heatmap(results[results[\"param_criterion\"]==\"log_loss\"].pivot(index = 'param_max_depth', columns = 'param_ccp_alpha', values = 'mean_test_score')))\n",
    "print(sns.heatmap(results[results[\"param_criterion\"]==\"gini\"].pivot(index = 'param_max_depth', columns = 'param_ccp_alpha', values = 'mean_test_score')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b257a8c",
   "metadata": {},
   "source": [
    "Een visualisatie van de ligging van de optimale waarden voor `'param_min_samples_leaf'` en `'param_min_samples_split'` per gekozen split criterium: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7959c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sns.heatmap(results[results[\"param_criterion\"]==\"entropy\"].pivot(index = 'param_min_samples_leaf', columns = 'param_min_samples_split', values = 'mean_test_score')))\n",
    "print(sns.heatmap(results[results[\"param_criterion\"]==\"log_loss\"].pivot(index = 'param_min_samples_leaf', columns = 'param_min_samples_split', values = 'mean_test_score')))\n",
    "\n",
    "#print(sns.heatmap(results[results[\"param_criterion\"]==\"gini\"].pivot(index = 'param_min_samples_leaf', columns = 'param_min_samples_split', values = 'mean_test_score')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd30288",
   "metadata": {},
   "source": [
    "Uit bovenstaande maken we op dat de modellen met de `' criterion = gini'` het doorgaans minder goed doen, de andere twee opties ontlopen elkaar niet veel. Bij `' criterion = log_loss'` liggen de beste waarden voor `'param_min_samples_leaf'` en `'param_min_samples_split'` rond de 0.003 resp. zo klein mogelijken de `param_ccp_alpha` kan best zo klein mogelijk (0) worden gekozen en `'param_max_depth'` rond de 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beste uit de bus vanuit random search: \n",
    "tuning_model_rand.cv_results_['params'][tuning_model_rand.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model_rand.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9aa95",
   "metadata": {},
   "source": [
    "#### Vervolgstappen\n",
    "Nu we een idee van de ligging van de parameters hebben waar de modelscore op de validatiesets het gemiddeld het beste lijkt te doen, zou een stap kunnen zijn in te zoomen in dat gebied met een gewone grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitie\n",
    "dtc_opt_rand = tuning_model_rand.best_estimator_\n",
    "\n",
    "#fitten op hele train dataset\n",
    "dtc_opt_rand.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96653e16",
   "metadata": {},
   "source": [
    "Maar dan nu een grid search in een kleiner gebied. De parameter `\"criterion\"` kiezen we vast `\"log_loss\"` evenals de `\"ccp_alpha\" = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ac74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rondom gevonden gebied, kleine stappen\n",
    "parameters3={\"max_depth\" : [3, 4, 5, 6] ,\n",
    "             \"min_samples_leaf\" : [0.0001, 0.0005, 0.001, 0.0015, 0.002, 0.0025, 0.003, 0.0035, 0.004, 0.0045]\n",
    "           }\n",
    "dtc_3 = DecisionTreeClassifier(criterion = \"log_loss\", ccp_alpha = 0,  random_state=999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe9ad4-fffd-4d0e-a1fd-b80b8e78a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model_3 = GridSearchCV(estimator = dtc_3, \n",
    "                            param_grid = parameters3,    # we doorlopen het zojuist gedefinieerde grid 'parameters2'\n",
    "                            scoring='accuracy',          # we kiezen modelscore: de accuracy\n",
    "                            cv=6,                        # we kiezen k = 6 in de k-fold CV\n",
    "                            verbose=1)                   # hiermee regel je de details van de output gedurende het trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21209f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model_3.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c884c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beste model: \", tuning_model_3.best_estimator_)\n",
    "print(\"Beste score:  accuracy = \", tuning_model_3.best_score_)\n",
    "print(\"Beste parameter combi: \", tuning_model_3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adca470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitie\n",
    "dtc_opt_3 = tuning_model_3.best_estimator_\n",
    "\n",
    "#fitten op hele train dataset\n",
    "dtc_opt_3.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dcbbea-97a4-49d1-a108-3e0cb344b0c1",
   "metadata": {},
   "source": [
    "#### Voorspelling op de test set\n",
    "Het nu geoptimaliseerde model testen we op de testset. Denk er wel aan het model nog eenmaal op de complete train dataset te trainen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87cb4c-6b20-4b7c-8669-e49541dcd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitie\n",
    "dtc_opt_3 = tuning_model_3.best_estimator_\n",
    "\n",
    "#fitten op hele train dataset\n",
    "dtc_opt_3.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e68a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorspellen op de test dataset - NB: wordt hier dus voor het eerst gebruikt!\n",
    "predicted_3_y = dtc_opt_3.predict(test_X)\n",
    "\n",
    "#accuracy op test dataset\n",
    "print(\"De accuracy op de testset = \", metrics.accuracy_score(test_y, predicted_3_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e3004",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 6. Baysian Search \n",
    "**< To do >**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d69db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
