{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc53274",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1>DataLab HvA - serie Machine Learning Python - Tech report 4</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92d689",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h2>Lineaire Regressie</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37623910",
   "metadata": {},
   "source": [
    "### 0. Doel van deze les\n",
    "Vanwege de serie lessen waarbinnen deze les valt is het hierin de insteek is om het gemaakte model te gaan vergelijken met andere andere Machine Learning modellen en daarbij een kwaliteitscriterium te hanteren waarmee *alle* modellen onderling vergelijkbaar zijn. Dit is de reden dat we werken met een test- en een trainset van onze data.\n",
    "**Je leert** \n",
    "- hoe je in Python met behulp van het package `sklearn` een Lineair Regressiemodel kunt maken\n",
    "- hoe je de geevalueerde modelcoëfficiënten van dit model kunt bekijken\n",
    "- hoe je dit model kunt gebruiken om voorspellingen te genereren op nieuwe data\n",
    "\n",
    "**Je leert niet:**\n",
    "- algemene theoretisch wiskundige achtergronden over Lineaire Regressie, hiervoor verwijzen we naar een les statistiek in je eigen opleiding of één van de vele online tutorials hierover.\n",
    "- bij meervoudige regressie: strategiën met betrekking tot het selecteren van de in het model te gebruiken variabelen (*feature selection*). \n",
    "- hoe je met het package `seaborn` eerste visuele verkenningen van de (variatie in de) data kan uitvoeren, zie hiervoor *Tech report 1: Introductie Machine Learning* uit deze serie.\n",
    "- hoe je data importeert en inlaadt in de python sessie, zie hiervoor echter wel [deze instructie](https://www.youtube.com/watch?v=1oBVx7pyuXo&list=PLwkTCAI_gJjW10xaAJpdqeQx7EQgFolfG&index=10) \n",
    "\n",
    "**Machine Learning framework**\n",
    "- Om een consistente leerlijn in de serie Machine Learning aan te houden kiezen we telkens voor een opzet waarin een inititeel model bepaald wordt o.b.v. een *deel* van de beschikbare data: de *train data*. Om het model te kunnen vergelijken met ándere modeltypen (waarbij andere algoritmen worden gebruikt) stellen we de voorspellende prestaties vast a.h.v. de nog niet gebruikte data: de *test data*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffe4c0",
   "metadata": {},
   "source": [
    "### 1. Laden van de benodigde packages\n",
    "Packages die je zelf nog niet hebt geinstalleerd dien je vooraf in Python te installeren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429d3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voor de dataset\n",
    "import seaborn as sns\n",
    "\n",
    "# Voor het bewerken en inspecteren van de data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Voor het afsplitsen van een train- en test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Voor het modelleren\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd14a4",
   "metadata": {},
   "source": [
    "### 2. Laden en prepareren van de data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e407b",
   "metadata": {},
   "source": [
    "We gebruiken als voorbeeld een dataset `'tips'`: \"*One waiter recorded information about each tip he received over a period of a few months working in one restaurant. He collected several variables*\". In totaal beschikken we over 244 waarnemingen. Lees eventueel meer over deze set [hier](https://rdrr.io/cran/reshape2/man/tips.html).   \n",
    "\n",
    "#### Laden en weergave data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87e46c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "(244, 7)\n",
      "total_bill     float64\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day           category\n",
      "time          category\n",
      "size             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Laden van een standaard dataset uit package seaborn \n",
    "data = sns.load_dataset('tips')\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(data.dtypes)\n",
    "\n",
    "#X = pd.get_dummies(data=X, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98451a",
   "metadata": {},
   "source": [
    "#### Dummy encoding categoriale variabelen\n",
    "We zien dat we te maken hebben met een aantal categoriale variabelen, het regressiemodel kan hier niet mee overweg (zie ook de korte toelichting op het modeltype hieronder). We maken hiervoor *dummie variabelen* aan. Om ervoor te zorgen dat deze onderling niet volledig gecorreleerd zijn zal er één dummy minder worden aangemaakt dan er mogelijke waarden zijn (`drop_first=True`) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c514582d",
   "metadata": {},
   "source": [
    "#### Split variabelen X en y\n",
    "In dit voorbeeld willen we de waarde voor `tip` gaan voorspellen, zie ook *sectie 3: Voorbeschouwing* verderop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74870365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent variables / explanatory variables\n",
    "X = data.drop('tip', axis=1)\n",
    "\n",
    "#dependent variable / response / target variable.\n",
    "y = data['tip']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ccfc79",
   "metadata": {},
   "source": [
    "#### Dummy encoding categoriale variabelen\n",
    "We zien dat we te maken hebben met een aantal categoriale variabelen, het regressiemodel kan hier niet mee overweg (zie ook de korte toelichting op het modeltype hieronder). We maken hiervoor *dummie variabelen* aan. Om ervoor te zorgen dat deze onderling niet volledig gecorreleerd zijn zal er één dummy minder worden aangemaakt dan er mogelijke waarden zijn (`drop_first=True`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16305358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "# drop = 'first' omdat we dummy-encoding willen toepassen\n",
    "enc = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# Alleen de categoriale variabelen\n",
    "X_trans =enc.fit_transform(X[['sex', 'smoker', 'day', 'time']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c335a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tijdelijke matrix met de niet-categoriale variabelen\n",
    "X_np = X.drop(['sex', 'smoker', 'day', 'time'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedd843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans = np.concatenate((X_np, X_trans), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b61e291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array(['Fri', 'Sat', 'Sun', 'Thur'], dtype=object),\n",
       " array(['Dinner', 'Lunch'], dtype=object)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1f9fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sex', 'smoker', 'day', 'time'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b232cab",
   "metadata": {},
   "source": [
    "#### Afsplitsen test data en train data\n",
    "Voor meer details over deze stap, zie *Tech report 2: Datapreparatie* uit deze serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7552e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 8)\n",
      "(74, 8)\n",
      "(170,)\n",
      "(74,)\n"
     ]
    }
   ],
   "source": [
    "# Split in training en test data \n",
    "# random_state kiezen zorgt voor reproduceerbaarheid van dit resultaat - gebruik dat ! Een andere waarde is uiteraard ook prima\n",
    "# we kiezen voor een verhouden train - test van 70% - 30%. Andere keuzen kunnen ook!\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_trans,y,test_size=0.30,random_state=999)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61780f58",
   "metadata": {},
   "source": [
    "### 3. Voorbeschouwing\n",
    "Zomaar modelleren doe je niet, eerst moeten we vaststellen wat we willen bereiken of welke vraag we zouden willen beantwoorden. Voor deze les zal dat worden:\n",
    "- Taak: stel een lineair regressie model op om de hoogte van de fooi te voorspellen op basis van de overige variabelen \n",
    "\n",
    "Vanuit de taak zullen we dus stellen:\n",
    "- De *onafhankelijke* variabelen ($x_i$) zijn de variabelen `total_bill`, `size`, `sex_Female`, `smoker_No`, `day_Fri`, `day_Sat`, `day_Sun`, `time_Dinner`, \n",
    "- De *afhankelijke* variabele ($y$) is de variabele `tip`\n",
    "\n",
    "We zijn, met bovengenoemde definitie van $x_i$ en $y$ dus op zoek naar het model:\n",
    "$$ y = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_k x_k +\\epsilon$$\n",
    "\n",
    "Met in ons geval $k = 8$\n",
    "\n",
    "Dat wil zeggen: we willen de *modelparameters* $\\alpha$ en $\\beta_i$ vaststellen. De term $\\epsilon$ drukt de *fout* uit die elke voorspelling onvermijdelijk zal hebben. De algoritmen in `sklearn` die ons dit model gaan geven zorgen ervoor dat deze *fout* (eigelijk: het kwadraat ervan) voor de voorspellingen op de gebruikte traindata gemiddeld genomen zo klein mogelijk zal zijn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5070f",
   "metadata": {},
   "source": [
    "### 4. Model schatten\n",
    "#### lees documentatie bij package\n",
    "Voordat we een model gaan schatten is het van belang dat je de documentatie van het algoritme dat we uit het package gaan gebruiken lezen. In dit geval is dat dus voor `LinearRegression()`, die lees je bijvoorbeeld online [hier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Alternatief is om de `help()` functie te gebruiken, zie hieronder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d3c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LinearRegression in module sklearn.linear_model._base object:\n",
      "\n",
      "class LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, LinearModel)\n",
      " |  LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      " |  to minimize the residual sum of squares between the observed targets in\n",
      " |  the dataset, and the targets predicted by the linear approximation.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be centered).\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup in case of sufficiently large problems, that is if firstly\n",
      " |      `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
      " |      to `True`. ``None`` means 1 unless in a\n",
      " |      :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
      " |      processors. See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive. This\n",
      " |      option is only supported for dense arrays.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  rank_ : int\n",
      " |      Rank of matrix `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  singular_ : array of shape (min(X, y),)\n",
      " |      Singular values of `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  intercept_ : float or array of shape (n_targets,)\n",
      " |      Independent term in the linear model. Set to 0.0 if\n",
      " |      `fit_intercept = False`.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  Ridge : Ridge regression addresses some of the\n",
      " |      problems of Ordinary Least Squares by imposing a penalty on the\n",
      " |      size of the coefficients with l2 regularization.\n",
      " |  Lasso : The Lasso is a linear model that estimates\n",
      " |      sparse coefficients with l1 regularization.\n",
      " |  ElasticNet : Elastic-Net is a linear regression\n",
      " |      model trained with both l1 and l2 -norm regularization of the\n",
      " |      coefficients.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
      " |  (scipy.optimize.nnls) wrapped as a predictor object.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_\n",
      " |  3.0...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted Estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We gaan de methode LinearRegression() uit het sklearn package gebruiken, inspecteer hiervoor de documentatie. Dat kan \n",
    "help(LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bd7ba",
   "metadata": {},
   "source": [
    "Zie bijvoorbeeld de parameter: `fit_intercept=True` (default waarde), als je die `=False` kiest zul je een $\\alpha = 0$ afdwingen in het model. Ook lees je dat er een *method*  `fit()` voor deze *object class* gedefinieerd is om het model te *fitten*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92aae34",
   "metadata": {},
   "source": [
    "#### model fitten\n",
    "We gebruiken dus de train data om een model te fitten. Dit is, zoals je ziet, een eenvoudig regeltje code. We geven het model een naam (`model_linreg`) zodat we het later weer opnieuw kunnen aanroepen / gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28dc8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Met model fitten default van package\n",
    "model_linreg = LinearRegression().fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161ee58",
   "metadata": {},
   "source": [
    "### 5. Model coëfficiënten en metrics van model zelf\n",
    "We stellen vast welke modelcoëfficiënten $\\alpha$ en $\\beta_i$ het model voor ons heeft geschat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c0e1ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.8667540547690167\n",
      "[beta_1, beta_2, ..., beta_8] = [ 0.09959159  0.12272968 -0.02809108 -0.30021809 -0.14944026 -0.15647015\n",
      " -0.13293045  0.06394865]\n"
     ]
    }
   ],
   "source": [
    "# Model mét constante\n",
    "# coefficiënt alpha\n",
    "print(\"alpha =\", model_linreg.intercept_)\n",
    "# coefficient beta\n",
    "print(\"[beta_1, beta_2, ..., beta_8] =\", model_linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d029999",
   "metadata": {},
   "source": [
    "### 6. Voorspellingen en perfomance op testset\n",
    "Hieronder genereren we voorspellingen van y op de testset. Tevens produceren we een modelscore in termen van prestatiematen (performance measures, metrics) op de testset. Voor meer toelichting daarover verwijzen we naar *Tech report 3: performance metrics regressie en classificatie*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "713226d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model_linreg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1d9e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE MAE op de testset =  0.8227245818612691\n",
      "DE MSE op de testset =  1.312539659095548\n",
      "DE RMSE op de testset =  1.1456612322565287\n",
      "DE MAPE op de testset =  0.2601572876744765\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#MAE\n",
    "print(\"DE MAE op de testset = \", metrics.mean_absolute_error(test_y, predicted_y))\n",
    "\n",
    "#MSE\n",
    "print(\"DE MSE op de testset = \", metrics.mean_squared_error(test_y, predicted_y))\n",
    "\n",
    "#RMSE\n",
    "print(\"DE RMSE op de testset = \", metrics.root_mean_squared_error(test_y, predicted_y))\n",
    "\n",
    "#MAPE\n",
    "print(\"DE MAPE op de testset = \", metrics.mean_absolute_percentage_error(test_y, predicted_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759609c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
